from pyspark.sql import SparkSession
from pyspark.sql.functions import *
import datetime
from filestructs import FileStructs

spark = SparkSession.builder.appName("Spark").getOrCreate()
df_stock_union = spark.createDataFrame([], FileStructs.DATA_STOCK)
df_stock_union.show()
df_stock = spark.read.schema(FileStructs.DATA_STOCK).csv("spark-study/stock-data_filestruct.csv", header=True, sep='\t')
df_stock.show()

    +-------------------+----------+----------+---------+-----------+
    |               date|open_price|high_price|low_price|close_price|
    +-------------------+----------+----------+---------+-----------+
    |2018-02-28 10:12:22|       142|       152|      142|        149|
    |2018-02-27 09:23:24|       149|       154|      149|        150|
    |2018-02-26 11:12:36|       152|       152|      151|        151|
    |2018-02-25 14:22:46|       151|       154|      151|        153|
    |2018-02-24 08:02:56|       152|       154|      152|        153|
    |2018-02-23 07:12:34|       154|       154|      151|        153|
    +-------------------+----------+----------+---------+-----------+

df_stock_union = df_stock_union.union(df_stock)
df_stock_union.show()
    +-------------------+----------+----------+---------+-----------+
    |               date|open_price|high_price|low_price|close_price|
    +-------------------+----------+----------+---------+-----------+
    |2018-02-28 10:12:22|       142|       152|      142|        149|
    |2018-02-27 09:23:24|       149|       154|      149|        150|
    |2018-02-26 11:12:36|       152|       152|      151|        151|
    |2018-02-25 14:22:46|       151|       154|      151|        153|
    |2018-02-24 08:02:56|       152|       154|      152|        153|
    |2018-02-23 07:12:34|       154|       154|      151|        153|
    +-------------------+----------+----------+---------+-----------+
    
df_stock_union.printSchema()
    root
     |-- date: timestamp (nullable = true)
     |-- open_price: decimal(10,0) (nullable = true)
     |-- high_price: decimal(10,0) (nullable = true)
     |-- low_price: decimal(10,0) (nullable = true)
     |-- close_price: decimal(10,0) (nullable = true)
df_select = df_stock_union.select('date', 'open_price')
df_select.show()
    +-------------------+----------+
    |               date|open_price|
    +-------------------+----------+
    |2018-02-28 10:12:22|       142|
    |2018-02-27 09:23:24|       149|
    |2018-02-26 11:12:36|       152|
    |2018-02-25 14:22:46|       151|
    |2018-02-24 08:02:56|       152|
    |2018-02-23 07:12:34|       154|
    +-------------------+----------+
df_select = df_select.filter(df_select.open_price==152)
df_select.show()
    +-------------------+----------+
    |               date|open_price|
    +-------------------+----------+
    |2018-02-26 11:12:36|       152|
    |2018-02-24 08:02:56|       152|
    +-------------------+----------+
from pyspark.sql.window import Window
# 同一dateでの当該項目の最初のNULLでない値を、NULLとなっている項目に代入
    w_date = (Window
        .partitionBy('date')
        .orderBy('open_price')
        .rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing))
    df_select = df_select.select(
        df_select["*"]
        , first("date", True).over(w_date).alias('date_new')
        , first("date", True).over(w_date).alias('date_new2')
    )
df_select.show()

    +-------------------+----------+-------------------+-------------------+
    |               date|open_price|           date_new|          date_new2|
    +-------------------+----------+-------------------+-------------------+
    |2018-02-26 11:12:36|       152|2018-02-26 11:12:36|2018-02-26 11:12:36|
    |2018-02-24 08:02:56|       152|2018-02-24 08:02:56|2018-02-24 08:02:56|
    +-------------------+----------+-------------------+-------------------+
# 時間修正 UTC => JST
df_select = df_select.withColumn('date_jst', df_select.date + expr('INTERVAL 9 HOURS')) 
df_select
df_select.show()
    +-------------------+----------+-------------------+-------------------+-------------------+
    |               date|open_price|           date_new|          date_new2|           date_jst|
    +-------------------+----------+-------------------+-------------------+-------------------+
    |2018-02-26 11:12:36|       152|2018-02-26 11:12:36|2018-02-26 11:12:36|2018-02-26 20:12:36|
    |2018-02-24 08:02:56|       152|2018-02-24 08:02:56|2018-02-24 08:02:56|2018-02-24 17:02:56|
    +-------------------+----------+-------------------+-------------------+-------------------+
df_select=df_select.withColumn('time_gmt', lit(1575383867))
df_select.show()
    +-------------------+----------+-------------------+-------------------+-------------------+----------+
    |               date|open_price|           date_new|          date_new2|           date_jst|  time_gmt|
    +-------------------+----------+-------------------+-------------------+-------------------+----------+
    |2018-02-26 11:12:36|       152|2018-02-26 11:12:36|2018-02-26 11:12:36|2018-02-26 20:12:36|1575383867|
    |2018-02-24 08:02:56|       152|2018-02-24 08:02:56|2018-02-24 08:02:56|2018-02-24 17:02:56|1575383867|
    +-------------------+----------+-------------------+-------------------+-------------------+----------+
